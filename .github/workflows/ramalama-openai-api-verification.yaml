# spdx-license-identifier: Apache-2.0

name: ramalama OpenAI API Verification

on:
  workflow_dispatch:
    inputs:
      repo:
        description: ramalama-stack repo to checkout
        required: false
        default: containers/ramalama-stack
      branch:
        description: ramalama-stack branch to checkout
        required: false
        default: main
  schedule:
    - cron: "21 21 * * *"

env:
  LC_ALL: en_US.UTF-8
  TMPDIR: /home/tmp
  VERIFICATION_RESULTS_DIR: /home/tmp/test_results
  INFERENCE_MODEL: llama3.3:70b-instruct-q4_K_M

defaults:
  run:
    shell: bash

permissions:
  contents: read

jobs:
  start-ec2-runner:
    runs-on: ubuntu-latest
    outputs:
      label: ${{ steps.start-ec2-runner.outputs.label }}
      ec2-instance-id: ${{ steps.start-ec2-runner.outputs.ec2-instance-id }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5 # v4.2.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Start EC2 runner
        id: start-ec2-runner
        uses: machulav/ec2-github-runner@a8c20fc0876503410b2b966c124abc2311984ce2 # v2.3.9
        with:
          mode: start
          github-token: ${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}
          ec2-image-id: ${{ vars.AWS_EC2_AMI }}
          ec2-instance-type: g6e.8xlarge
          subnet-id: subnet-02d230cffd9385bd4
          security-group-id: sg-06300447c4a5fbef3
          iam-role-name: instructlab-ci-runner
          aws-resource-tags: >
            [
              {"Key": "Name", "Value": "instructlab-ci-github-runner"},
              {"Key": "GitHubRepository", "Value": "${{ github.repository }}"},
              {"Key": "GitHubRef", "Value": "${{ github.ref }}"}
            ]

  verification:
    needs:
      - start-ec2-runner
    runs-on: ${{ needs.start-ec2-runner.outputs.label }}

    steps:
      - name: Install Packages
        run: |
          cat /etc/os-release
          mkdir -p "${TMPDIR}"
          mkdir -p "${VERIFICATION_RESULTS_DIR}"
          sudo dnf install -y gcc gcc-c++ make git python3.11 python3.11-devel python3.11-pip

      - name: Checkout meta-llama/llama-stack
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: "meta-llama/llama-stack"
          ref: "main"
          # https://github.com/actions/checkout/issues/249
          fetch-depth: 0

      - name: Checkout containers/ramalama-stack
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository:  ${{ inputs.repo || 'containers/ramalama-stack' }}
          ref: ${{ inputs.branch || 'main' }}
          path: "ramalama-stack"
          # https://github.com/actions/checkout/issues/249
          fetch-depth: 0

      - name: Install dependencies
        run: |
          export PATH="/home/ec2-user/.local/bin:/usr/local/cuda/bin:$PATH"
          nvidia-smi

          export UV_PYTHON_PREFERENCE=only-system
          python3.11 -m pip install uv
          uv sync --extra dev
          source .venv/bin/activate
          python3.11 -m ensurepip
          uv pip install -e .
          uv pip install pytest-json-report
          
          uv pip install ramalama

      - name: Run servers
        run: |
          source .venv/bin/activate

          ramalama pull "${INFERENCE_MODEL}"
          ramalama serve "${INFERENCE_MODEL}" 2>&1 | tee ramalama.log &
          # shellcheck disable=SC2016
          timeout 600 bash -c 'while [[ "$(curl -s -o /dev/null -w ''%{http_code}'' http://localhost:8080/v1/models)" != "200" ]]; do sleep 5; done' || false

          cd ramalama-stack
          uv run llama stack run --image-type venv --port 8321 run.yaml 2>&1 | tee llama_stack.log &
          curl --retry-connrefused --retry 15 --retry-delay 5 http://localhost:8321/v1/openai/v1/models
        env:
          HOME: ${{ env.TMPDIR }}
          HF_TOKEN: ${{ secrets.HF_TOKEN }}

      - name: Run ramalama verification tests
        run: |
          source .venv/bin/activate

          cat <<-EOF > tests/verifications/conf/ramalama.yaml
          base_url: http://localhost:8080/v1
          api_key_var: OPENAI_API_KEY
          models:
          - ${INFERENCE_MODEL}
          model_display_names:
            ${INFERENCE_MODEL}: ${INFERENCE_MODEL}
          test_exclusions:
            ${INFERENCE_MODEL}:
            - test_chat_non_streaming_image
            - test_chat_streaming_image
            - test_chat_multi_turn_multiple_images
          EOF

          cat <<-EOF > tests/verifications/conf/ramalama-llama-stack.yaml
          base_url: http://localhost:8321/v1/openai/v1
          api_key_var: OPENAI_API_KEY
          models:
          - ${INFERENCE_MODEL}
          model_display_names:
            ${INFERENCE_MODEL}: ${INFERENCE_MODEL}
          test_exclusions:
            ${INFERENCE_MODEL}:
            - test_chat_non_streaming_image
            - test_chat_streaming_image
            - test_chat_multi_turn_multiple_images
          EOF

          tail -f ramalama.log &
          tail -f ramalama-stack/llama_stack.log &

          python3.11 -m pytest -s -v tests/verifications/openai_api/test_chat_completion.py --provider=ramalama --json-report --json-report-file="${VERIFICATION_RESULTS_DIR}/ramalama.json" || echo "some ramalama verification tests failed"

          python3.11 -m pytest -s -v tests/verifications/openai_api/test_chat_completion.py --provider=ramalama-llama-stack --json-report --json-report-file="${VERIFICATION_RESULTS_DIR}/ramalama-llama-stack.json" || echo "some ramalama-llama-stack verification tests failed"
        env:
          OPENAI_API_KEY: fake

      - name: Upload test artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: openai-api-verification-results
          path: ${{ env.VERIFICATION_RESULTS_DIR }}

  publish-results:
    name: publish-results
    runs-on: ubuntu-latest
    needs: verification
    permissions:
      # allow pushing to the github repo
      contents: write
    steps:
      - name: Checkout this repo
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          ref: "main"
          # https://github.com/actions/checkout/issues/249
          fetch-depth: 0

      - name: Download report artifact
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          name: openai-api-verification-results
          path: artifacts

      - name: Add the new verification results
        run: |
          TODAY="$(date -Idate)"
          export TODAY
          ls -l artifacts/
          mkdir -p openai-api-verification/latest
          mkdir -p "openai-api-verification/${TODAY}"
          cp artifacts/*.json openai-api-verification/latest/
          cp artifacts/*.json "openai-api-verification/${TODAY}/"

      - name: Push new results
        run: |
          git config --global user.name "Ben Browning"
          git config --global user.email "bbrownin@redhat.com"

          git add openai-api-verification
          git commit -m "Verification results for $(date -Idate)"
          git push
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  stop-ec2-runner:
    needs:
      - start-ec2-runner
      - verification
      - publish-results
    runs-on: ubuntu-latest
    if: ${{ always() }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@f24d7193d98baebaeacc7e2227925dd47cc267f5 # v4.2.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Stop EC2 runner
        uses: machulav/ec2-github-runner@a8c20fc0876503410b2b966c124abc2311984ce2 # v2.3.9
        with:
          mode: stop
          github-token: ${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}
          label: ${{ needs.start-ec2-runner.outputs.label }}
          ec2-instance-id: ${{ needs.start-ec2-runner.outputs.ec2-instance-id }}

  workflow-complete:
    # we don't want to block PRs on failed EC2 cleanup
    # so not requiring "stop-ec2-runner" as well
    needs: ["start-ec2-runner", "verification", "publish-results"]
    runs-on: ubuntu-latest
    steps:
      - name: Workflow Complete
        run: echo "Workflow Complete"
