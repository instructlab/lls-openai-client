# spdx-license-identifier: Apache-2.0

name: OpenAI API Verification

on:
  workflow_dispatch:

env:
  LC_ALL: en_US.UTF-8
  TMPDIR: /home/tmp

defaults:
  run:
    shell: bash

permissions:
  contents: read

jobs:
  start-ec2-runner:
    runs-on: ubuntu-latest
    outputs:
      label: ${{ steps.start-ec2-runner.outputs.label }}
      ec2-instance-id: ${{ steps.start-ec2-runner.outputs.ec2-instance-id }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Start EC2 runner
        id: start-ec2-runner
        uses: machulav/ec2-github-runner@a8c20fc0876503410b2b966c124abc2311984ce2 # v2.3.9
        with:
          mode: start
          github-token: ${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}
          ec2-image-id: ${{ vars.AWS_EC2_AMI }}
          ec2-instance-type: g4dn.2xlarge
          subnet-id: subnet-02d230cffd9385bd4
          security-group-id: sg-06300447c4a5fbef3
          iam-role-name: instructlab-ci-runner
          aws-resource-tags: >
            [
              {"Key": "Name", "Value": "instructlab-ci-github-runner"},
              {"Key": "GitHubRepository", "Value": "${{ github.repository }}"},
              {"Key": "GitHubRef", "Value": "${{ github.ref }}"}
            ]

  verification:
    needs:
      - start-ec2-runner
    runs-on: ${{ needs.start-ec2-runner.outputs.label }}

    steps:
      - name: Install Packages
        run: |
          cat /etc/os-release
          mkdir -p "${TMPDIR}"
          sudo dnf install -y gcc gcc-c++ make git python3.11 python3.11-devel

      - name: Checkout meta-llama/llama-stack
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          repository: "meta-llama/llama-stack"
          ref: "main"
          # https://github.com/actions/checkout/issues/249
          fetch-depth: 0

      - name: Install dependencies
        run: |
          export PATH="/home/ec2-user/.local/bin:/usr/local/cuda/bin:$PATH"
          nvidia-smi

          export UV_PYTHON_PREFERENCE=only-system
          python3.11 -m pip install uv
          uv sync --extra dev
          uv pip install -e .
          uv pip install pytest-json-report
          uv pip install "vllm>=0.8.0"
          uv run llama stack build --template remote-vllm --image-type venv

      - name: Run servers
        run: |
          uv run vllm serve "${INFERENCE_MODEL}" --port 8000 --enable-auto-tool-choice --tool-call-parser llama3_json --max-model-len 32000
          uv run llama stack run --image-type venv --port 8321 remote-vllm &
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
          VLLM_URL: "http://localhost:8000/v1"
          INFERENCE_MODEL: "meta-llama/Llama-3.2-3B-Instruct"

      - name: Wait for servers to come up
        run: |
          curl --retry-connrefused --retry 50 --retry-delay 30 http://localhost:8000/v1/models
          curl --retry-connrefused --retry 5 --retry-delay 3 http://localhost:8321/v1/openai/v1/models

      - name: Run verification tests
        run: |
          source .venv/bin/activate
          python3.11 -m pytest -s -v tests/verifications/openai_api/test_chat_completion.py

  stop-ec2-runner:
    needs:
      - start-ec2-runner
      - verification
    runs-on: ubuntu-latest
    if: ${{ always() }}
    steps:
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@ececac1a45f3b08a01d2dd070d28d111c5fe6722 # v4.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Stop EC2 runner
        uses: machulav/ec2-github-runner@a8c20fc0876503410b2b966c124abc2311984ce2 # v2.3.9
        with:
          mode: stop
          github-token: ${{ secrets.GH_PERSONAL_ACCESS_TOKEN }}
          label: ${{ needs.start-ec2-runner.outputs.label }}
          ec2-instance-id: ${{ needs.start-ec2-runner.outputs.ec2-instance-id }}

  workflow-complete:
    # we don't want to block PRs on failed EC2 cleanup
    # so not requiring "stop-ec2-runner" as well
    needs: ["start-ec2-runner", "verification"]
    runs-on: ubuntu-latest
    steps:
      - name: Workflow Complete
        run: echo "Workflow Complete"
